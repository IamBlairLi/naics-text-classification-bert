{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a59c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'business_name': 'ACME Plumbing',\n",
       "  'text': 'plumbing leak repair drain cleaning water heater installation',\n",
       "  'label': '238220'},\n",
       " {'business_name': 'Bright Spark Electric',\n",
       "  'text': 'electrical contractor wiring panel upgrade lighting installation',\n",
       "  'label': '238210'},\n",
       " {'business_name': 'CoolAir HVAC',\n",
       "  'text': 'heating air conditioning hvac furnace installation maintenance',\n",
       "  'label': '238220'},\n",
       " {'business_name': 'RoofPro',\n",
       "  'text': 'roofing contractor shingle replacement gutter repair storm damage',\n",
       "  'label': '238160'},\n",
       " {'business_name': 'FixIt Industrial',\n",
       "  'text': 'industrial equipment repair maintenance machine service technician',\n",
       "  'label': '811310'},\n",
       " {'business_name': 'PipeSupply Wholesale',\n",
       "  'text': 'plumbing supplies wholesale pipes valves fittings distributor',\n",
       "  'label': '423720'},\n",
       " {'business_name': 'Drain Masters',\n",
       "  'text': 'drain cleaning sewer line unclogging plumbing emergency service',\n",
       "  'label': '238220'},\n",
       " {'business_name': 'PowerGrid Wiring',\n",
       "  'text': 'wiring installation low voltage cabling electrical service',\n",
       "  'label': '238210'},\n",
       " {'business_name': 'Gutter & Roof',\n",
       "  'text': 'gutter cleaning roof repair shingles flashing',\n",
       "  'label': '238160'},\n",
       " {'business_name': 'MachineCare',\n",
       "  'text': 'commercial machinery repair preventive maintenance industrial service',\n",
       "  'label': '811310'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.training.dataset import load_jsonl, build_label_maps, NaicsTextDataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "rows=load_jsonl('data/train.jsonl')\n",
    "rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220db100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'238160': 0, '238210': 1, '238220': 2, '423720': 3, '811310': 4}\n",
      "{0: '238160', 1: '238210', 2: '238220', 3: '423720', 4: '811310'}\n"
     ]
    }
   ],
   "source": [
    "l2i,i2l=build_label_maps(rows)\n",
    "print(l2i)\n",
    "print(i2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4178f644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok=AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5f0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.training.dataset.NaicsTextDataset at 0x159f338e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=NaicsTextDataset(rows,l2i,tok,128)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46228004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  9353,  4168, 27902, 27902, 17271,  7192, 12475,  9344,  2300,\n",
       "          3684,  2121,  8272,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(2)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=ds[0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1258b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> torch.Size([128]) torch.Size([128]) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "print(type(x), x['input_ids'].shape, x['attention_mask'].shape, x['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a3483a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "print(batch[\"input_ids\"].shape)       # torch.Size([4, 128])\n",
    "print(batch[\"attention_mask\"].shape)  # torch.Size([4, 128])\n",
    "print(batch[\"labels\"].shape)          # torch.Size([4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed80963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "torch.Size([128])\n",
      "tensor(2) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 假设你项目里有这个函数：build_label_maps(rows) -> (l2i, i2l)\n",
    "# 假设你已经定义好了 NaicsTextDataset\n",
    "\n",
    "def read_jsonl_head(path: str, n: int) -> List[Dict]:\n",
    "    rows: List[Dict] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "            if len(rows) >= n:\n",
    "                break\n",
    "    return rows\n",
    "\n",
    "rows = read_jsonl_head(\"data/train.jsonl\", 5)\n",
    "\n",
    "l2i, i2l = build_label_maps(rows)  # 你项目里一般是从 train rows 建\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "ds = NaicsTextDataset(rows, l2i, tok, 128)\n",
    "\n",
    "print(ds[0].keys())\n",
    "print(ds[0][\"input_ids\"].shape)\n",
    "print(ds[0][\"labels\"], ds[0][\"labels\"].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32034124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128])\n",
      "sanity check passed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = ds[0]\n",
    "print(x[\"input_ids\"].shape)\n",
    "assert x[\"input_ids\"].ndim == 1\n",
    "assert x[\"labels\"].dtype == torch.long\n",
    "print(\"sanity check passed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f583055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128])\n",
      "torch.Size([4, 128])\n",
      "torch.Size([4])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x159f30fd0>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dl = DataLoader(ds, batch_size=4, shuffle=False)\n",
    "batch = next(iter(dl))\n",
    "print(batch[\"input_ids\"].shape)       # torch.Size([4, 128])\n",
    "print(batch[\"attention_mask\"].shape)  # torch.Size([4, 128])\n",
    "print(batch[\"labels\"].shape)          # torch.Size([4])\n",
    "print(dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d75fdaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = len(l2i)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels,\n",
    "    id2label=i2l,      # 可选：让输出更可读（预测时显示 label 名）\n",
    "    label2id=l2i,      # 可选：同上\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4bec634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "##training\n",
    "\n",
    "\n",
    "%python src.training.train configs/train.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.naics_inference.inference import InferenceModel; \n",
    "m=InferenceModel('artifacts/distilbert_naics'); \n",
    "print(m.predict('ACME Plumbing leak repair drain cleaning water heater', topk=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "684b5ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default_max_length: 128\n",
      "label_list len: 5 sample: ['238160', '238210', '238220']\n",
      "<class 'list'> 5 ['238160', '238210', '238220']\n",
      "input_ids shape: torch.Size([1, 128])\n",
      "mask tail: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "logits shape: (5,) top_idx: [2, 1, 0]\n",
      "[Prediction(code='238220', prob=0.32129210233688354), Prediction(code='238210', prob=0.18525734543800354), Prediction(code='238160', prob=0.17992505431175232)]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.naics_inference.inference as inf\n",
    "\n",
    "importlib.reload(inf)\n",
    "\n",
    "from src.naics_inference.inference import InferenceModel\n",
    "m = InferenceModel(\"artifacts/distilbert_naics\")\n",
    "print(m.predict(\"ACME Plumbing\", \"leak repair drain cleaning water heater\", topk=3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "655da73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(business_name: str, text: str, topk: int = 3, max_length: int = 128) -> List[src.naics_inference.inference.Prediction]\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.signature(m.predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92dc9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([1, 128])\n",
      "mask tail: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "logits shape: (5,) top_idx: [2, 1, 0]\n",
      "[Prediction(code='238220', prob=0.32129210233688354), Prediction(code='238210', prob=0.18525731563568115), Prediction(code='238160', prob=0.17992505431175232)]\n"
     ]
    }
   ],
   "source": [
    "print(m.predict(\"ACME Plumbing\", \"leak repair drain cleaning water heater\", topk=3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
